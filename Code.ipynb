{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07985105-5018-48af-8cc3-0eeb446eff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d8cce-2f3b-4b0a-a236-8e36594ff47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "class_label = {v: k for k, v in label_class.items()}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "RESIZE = 48\n",
    "BATCH_SIZE = 128\n",
    "PATH = 'D:\\AI Courses\\Semester 3\\Computer Vision\\Term Project\\model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'Model': {\n",
    "        'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((RESIZE, RESIZE)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'other':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((RESIZE, RESIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    },\n",
    "    'Others': {\n",
    "        'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'other':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223637b6-c5ff-43b7-95de-62b250ebc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_path = 'images/train/'\n",
    "val_base_path = 'images/validation/'\n",
    "\n",
    "classes = list(label_class.values())\n",
    "\n",
    "tr_paths, tr_lbls = [], []\n",
    "val_paths, val_lbls = [], []\n",
    "\n",
    "for each in classes:\n",
    "\n",
    "    full_path = train_base_path + each + '/'\n",
    "    num_items = os.listdir(full_path)\n",
    "    for itm in num_items:\n",
    "        tr_paths.append(full_path + itm)\n",
    "        tr_lbls.append(class_label[each])\n",
    "        \n",
    "    full_path = val_base_path + each + '/'\n",
    "    num_items = os.listdir(full_path)\n",
    "    for itm in num_items:\n",
    "        val_paths.append(full_path + itm)\n",
    "        val_lbls.append(class_label[each])\n",
    "\n",
    "\n",
    "tr_dict = {'img_id': tr_paths, 'label':tr_lbls}\n",
    "val_dict = {'img_id': val_paths, 'label':val_lbls}\n",
    "\n",
    "tr_df = pd.DataFrame(tr_dict)\n",
    "val_df = pd.DataFrame(val_dict)\n",
    "\n",
    "del tr_dict, val_dict, tr_lbls, val_lbls, tr_paths, val_paths, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ae347",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78414056",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(label_class.values()), list(tr_df['label'].value_counts().sort_index()))\n",
    "plt.xlabel(\"Emotion Classes\") \n",
    "plt.ylabel(\"No. of Samples per Emotion Class\") \n",
    "plt.title(\"Emotion Classes and Their Number of Samples\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, shuffle_data=True):\n",
    "\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        if shuffle_data:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple:\n",
    "        img = Image.open(self.df.iloc[idx, 0]).convert(\"RGB\")\n",
    "        lbl = self.df.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a80654-9d05-4b71-97fd-a2c887b47b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_model_dt = ImageDataset(tr_df, data_transforms['Model']['train'])\n",
    "val_model_dt = ImageDataset(val_df, data_transforms['Model']['other'])\n",
    "tr_other_dt = ImageDataset(tr_df, data_transforms['Others']['train'])\n",
    "val_other_dt = ImageDataset(val_df, data_transforms['Others']['other'])\n",
    "\n",
    "tr_model_loader = DataLoader(tr_model_dt, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_model_loader = DataLoader(val_model_dt, batch_size=BATCH_SIZE, shuffle=True)\n",
    "tr_other_loader = DataLoader(tr_other_dt, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_other_loader = DataLoader(val_other_dt, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "dataloaders = {\n",
    "    'Model': {\n",
    "        'train': tr_model_loader,\n",
    "        'validation': val_model_loader\n",
    "    },\n",
    "    'Others': {\n",
    "        'train': tr_other_loader,\n",
    "        'validation': val_other_loader\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83befa68-db62-4ea7-97dd-adbaa0493ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "random_indices = np.random.randint(0, len(tr_model_dt), num_samples)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = tr_model_dt[idx]\n",
    "    image = image.permute(1, 2, 0)\n",
    "    axes[i].imshow(np.uint8(np.array(image)))\n",
    "    axes[i].set_title(f\"Emotion: {label_class[label]}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tr_model_loader, val_model_loader, tr_model_dt, val_model_dt, tr_other_loader, val_other_loader, tr_other_dt, val_other_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d9f35-26f1-40fb-8aae-23b12ecd73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(num_features, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 3 * 3, 256, True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout1d(0.1),\n",
    "            nn.Linear(256, 128, True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout1d(0.1),\n",
    "            nn.Linear(128, 7, True),\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e3caa-29b5-4028-af06-cb7f8d1c5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model, criterion, optimizer, num_epochs=3, return_loss_acc=True):\n",
    "    \n",
    "    if return_loss_acc:\n",
    "        tr_val_history = {'train': [], 'validation': []}\n",
    "        tr_val_acc_history = {'train': [], 'validation': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 50)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            with tqdm(data[phase], unit='batch', position=0, leave=True) as pbar:\n",
    "                for img, lbl in pbar:\n",
    "\n",
    "                    pbar.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "                    img = img.to(device)\n",
    "                    lbl = lbl.to(device)\n",
    "                    outputs = model(img)\n",
    "                    loss = criterion(outputs, lbl)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    _, preds = (torch.max(outputs, 1))\n",
    "                    running_loss += loss.item()\n",
    "                    running_corrects += torch.sum(preds == lbl.data)\n",
    "                    pbar.set_postfix(loss=loss.item() / BATCH_SIZE, accuracy=torch.sum(preds == lbl.data).item() / BATCH_SIZE)\n",
    "\n",
    "            epoch_loss = running_loss / len(data[phase])\n",
    "            epoch_acc = running_corrects.double() / len(data[phase])\n",
    "\n",
    "            if return_loss_acc:\n",
    "                tr_val_history[phase].append(epoch_loss)\n",
    "                tr_val_acc_history[phase].append(epoch_acc.item())\n",
    "            \n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "            \n",
    "    if return_loss_acc:\n",
    "        return model, (tr_val_history, tr_val_acc_history)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1cfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(3).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH = 30\n",
    "\n",
    "model_trained, history = train_model(dataloaders['Model'], model, criterion, opt, EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[0]['train'], label='Train Loss')\n",
    "    plt.plot(history[0]['validation'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[1]['train'], label='Train Accuracy')\n",
    "    plt.plot(history[1]['validation'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy in %')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441a8c6-814c-4594-9b86-46407fcb8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beda478",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trained, './model/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderer(model, data):\n",
    "\n",
    "    face_classifier = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        faces = face_classifier.detectMultiScale(frame)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "            roi = frame[y:y + h, x:x + w]\n",
    "            roi = cv.resize(roi, (48, 48), interpolation=cv.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "            if np.sum([roi]) != 0:\n",
    "                roi = data['other'](Image.fromarray(roi))\n",
    "                roi = roi.reshape((1, roi.shape[0], roi.shape[1], roi.shape[2])).to(device)\n",
    "                prediction = model(roi)\n",
    "                label = label_class[torch.max(prediction, 1).indices.item()]\n",
    "                label_position = (x, y)\n",
    "                cv.putText(frame, label, label_position, cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv.putText(frame, 'No Faces', (30, 80), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv.imshow('Emotion Detector',frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/model.pth'\n",
    "model = torch.load(PATH)\n",
    "renderer(model, data_transforms['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(weights='DEFAULT')\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(resnet.fc.in_features, 7),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "\n",
    "EPOCH = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(resnet.parameters(), lr = 0.001)\n",
    "\n",
    "resnet_trained, history = train_model(dataloaders['Others'], resnet, criterion, opt, EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddcbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_trained, './model/resnet.pth')\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8218f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/resnet.pth'\n",
    "resnet = torch.load(PATH)\n",
    "renderer(resnet, data_transforms['Others'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg11_bn(weights='DEFAULT')\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=4096, out_features=7, bias=True))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH = 10\n",
    "model_trained, history = train_model(dataloaders['Others'], model, criterion, opt, EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb58148",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trained, './model/vgg.pth')\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74cc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    model.eval()\n",
    "    \n",
    "    with tqdm(data, unit='batch', position=0, leave=True) as pbar:\n",
    "        for img, lbl in pbar:\n",
    "\n",
    "            pbar.set_description(f\"Evaluating\")\n",
    "\n",
    "            img = img.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "            outputs = model(img)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y = y + [*np.array(lbl.cpu())]\n",
    "            y_pred = y_pred + [*np.array(preds.cpu())]\n",
    "    \n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b478fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/vgg.pth'\n",
    "vgg = torch.load(PATH)\n",
    "evaluate(vgg, dataloaders['Others']['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/resnet.pth'\n",
    "vgg = torch.load(PATH)\n",
    "evaluate(vgg, dataloaders['Others']['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bde684",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/model.pth'\n",
    "cnn = torch.load(PATH)\n",
    "evaluate(cnn, dataloaders['Model']['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af600be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model/model.pth'\n",
    "model = torch.load(PATH)\n",
    "renderer(vgg, data_transforms['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a14c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
